{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "\n",
    "with graph.as_default():\n",
    "    hello = tf.constant(\"Hello TensorFlow\")\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = 2\n",
    "y = 3\n",
    "\n",
    "z = tf.add(x, y, name=\"Add\")\n",
    "\n",
    "z_value = z.numpy()\n",
    "print(z_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "a = tf.multiply(8, 5)\n",
    "b = tf.multiply(a, 1)\n",
    "\n",
    "b_value = b.numpy()\n",
    "print(b_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "a = tf.multiply(8, 5)\n",
    "b = tf.multiply(4, 3)\n",
    "\n",
    "b_value = b.numpy()\n",
    "print(b_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    val = tf.multiply(3, 3)\n",
    "\n",
    "    with tf.compat.v1.Session() as session:\n",
    "        print(session.run(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=13>\n",
      "[[ 0.14107606  0.43629068  0.37619492 ...  0.1962083   0.15006424\n",
      "   0.23534477]\n",
      " [ 0.1303095  -0.09229585  0.09278669 ...  0.0470362  -0.25075448\n",
      "  -0.00960788]\n",
      " [ 0.36435005  0.35983106 -0.4004232  ...  0.20639211 -0.15153217\n",
      "   0.22244626]\n",
      " ...\n",
      " [ 0.2629911  -0.09785084  0.17406967 ...  0.0602855  -0.31937712\n",
      "   0.61378646]\n",
      " [-0.22790518  0.2446264  -0.41563493 ... -0.20926593 -0.09963737\n",
      "  -0.04379675]\n",
      " [-0.76142555 -0.07344237  0.2681341  ... -0.02527711  0.3336119\n",
      "  -0.28008288]]\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(13)\n",
    "print(x)\n",
    "\n",
    "y = tf.Variable(tf.random.normal(shape=[500, 111], stddev=0.35), name=\"weights\")\n",
    "y = y.numpy()\n",
    "print(y)\n",
    "\n",
    "weights = tf.Variable(22, name=\"weights_1\")\n",
    "W2 = tf.Variable(weights.read_value(), name=\"weights_2\")\n",
    "W2 = W2.numpy()\n",
    "print(W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1212\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "\n",
    "with graph.as_default():\n",
    "    x = tf.compat.v1.Variable(1212)\n",
    "    init = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "    with tf.compat.v1.Session() as session:\n",
    "        session.run(init)\n",
    "        print(session.run(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "W3 = tf.compat.v1.get_variable(\n",
    "    name=\"weights\",\n",
    "    shape=[500, 111],\n",
    "    initializer=tf.compat.v1.random_normal_initializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scope/x:0\n",
      "scope/x:0\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.variable_scope(\"scope\"):\n",
    "    a = tf.compat.v1.get_variable(\"x\", [2])\n",
    "\n",
    "with tf.compat.v1.variable_scope(\"scope\", reuse=True):\n",
    "    b = tf.compat.v1.get_variable(\"x\", [2])\n",
    "\n",
    "print(a.name)\n",
    "print(b.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_5:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(13)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.  5.]\n",
      " [ 6.  7.]\n",
      " [ 8.  9.]\n",
      " [10. 11.]]\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "x = tf.compat.v1.placeholder(\"float\", [None, 2])\n",
    "y = x + 3\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    x_val = [\n",
    "        [1, 2],\n",
    "        [3, 4],\n",
    "        [5, 6],\n",
    "        [7, 8],\n",
    "    ]\n",
    "    result = sess.run(y, feed_dict={x: x_val})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_9168\\4250927850.py:14: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_9168\\4250927850.py:14: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# TensorBoard\n",
    "\n",
    "x = tf.constant(1, name=\"x\")\n",
    "y = tf.constant(1, name=\"y\")\n",
    "a = tf.constant(3, name=\"a\")\n",
    "b = tf.constant(3, name=\"b\")\n",
    "\n",
    "prod1 = tf.multiply(x, y, name=\"prod1\")\n",
    "prod2 = tf.multiply(a, b, name=\"prod2\")\n",
    "\n",
    "sum = tf.add(prod1, prod2, name=\"sum\")\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    writer = tf.compat.v1.summary.FileWriter(logdir=\"./graphs\", graph=sess.graph)\n",
    "    print(sess.run(sum))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir=graphs --port=8001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten digits classification using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 6s 1us/step\n",
      "No of images in training set: (60000, 28, 28)\n",
      "No of labels in training set: (60000,)\n",
      "No of images in test set: (10000, 28, 28)\n",
      "No of labels in test set: (10000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the images to a range of 0 to 1\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "# Check the shape of the datasets\n",
    "print(\"No of images in training set: {}\".format(train_images.shape))\n",
    "print(\"No of labels in training set: {}\".format(train_labels.shape))\n",
    "print(\"No of images in test set: {}\".format(test_images.shape))\n",
    "print(\"No of labels in test set: {}\".format(test_labels.shape))\n",
    "# Display the first training image\n",
    "\n",
    "img1 = train_images[1].reshape(28,28)\n",
    "plt.imshow(img1, cmap='Greys')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 21s 69ms/step - loss: 0.9804 - accuracy: 0.7535 - val_loss: 0.3879 - val_accuracy: 0.8974\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 18s 59ms/step - loss: 0.3623 - accuracy: 0.8993 - val_loss: 0.2815 - val_accuracy: 0.9195\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 20s 66ms/step - loss: 0.2753 - accuracy: 0.9205 - val_loss: 0.2419 - val_accuracy: 0.9307\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 18s 61ms/step - loss: 0.2432 - accuracy: 0.9292 - val_loss: 0.2233 - val_accuracy: 0.9337\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 17s 57ms/step - loss: 0.2109 - accuracy: 0.9396 - val_loss: 0.1905 - val_accuracy: 0.9445\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 16s 54ms/step - loss: 0.2048 - accuracy: 0.9418 - val_loss: 0.1720 - val_accuracy: 0.9504\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 17s 58ms/step - loss: 0.1754 - accuracy: 0.9496 - val_loss: 0.1826 - val_accuracy: 0.9463\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 18s 62ms/step - loss: 0.1697 - accuracy: 0.9522 - val_loss: 0.1553 - val_accuracy: 0.9532\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 19s 65ms/step - loss: 0.1496 - accuracy: 0.9561 - val_loss: 0.1463 - val_accuracy: 0.9567\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 18s 59ms/step - loss: 0.1433 - accuracy: 0.9596 - val_loss: 0.1459 - val_accuracy: 0.9556\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.1459 - accuracy: 0.9556\n",
      "\n",
      "Test accuracy: 0.9556\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "# forward and backward propagation is automatically done in keras tensorflow. So it is not done manually. \n",
    "# Load the MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the images\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "# Define the number of neurons in each layer\n",
    "num_input = 784\n",
    "num_hidden1 = 512\n",
    "num_hidden2 = 256\n",
    "num_hidden3 = 128\n",
    "num_output = 10\n",
    "\n",
    "# Build the model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Flatten(input_shape=(28, 28)))  # Flatten the input images\n",
    "model.add(layers.Dense(num_hidden1, activation='relu', kernel_initializer='truncated_normal'))\n",
    "model.add(layers.Dense(num_hidden2, activation='relu', kernel_initializer='truncated_normal'))\n",
    "model.add(layers.Dense(num_hidden3, activation='relu', kernel_initializer='truncated_normal'))\n",
    "model.add(layers.Dense(num_output, activation='sigmoid'))  # Output layer with softmax\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "              loss=SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Create a log directory for TensorBoard\n",
    "log_dir = \"logs/fit/\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir, histogram_freq=1)\n",
    "\n",
    "# Custom callback for logging test metrics\n",
    "class CustomLoggingCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Evaluate the model on the test set\n",
    "        test_loss, test_accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
    "        \n",
    "        # Log the test metrics\n",
    "        tf.summary.scalar(\"Test Accuracy\", test_accuracy, step=epoch)\n",
    "        tf.summary.scalar(\"Test Loss\", test_loss, step=epoch)\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_data=(test_images, test_labels), steps_per_epoch=300)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f'\\nTest accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Eager Execution is directly implemented here in tensorflow 2.0\n",
    "\n",
    "x = tf.constant(11)\n",
    "y = tf.constant(11)\n",
    "z = x*y\n",
    "print(z)\n",
    "z.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sum: [4. 4. 4.]\n",
      "\n",
      "Difference: [-2.  0.  2.]\n",
      "\n",
      "Product: [3. 4. 3.]\n",
      "\n",
      "Division: [0.33333334 1.         3.        ]\n",
      "\n",
      "Dot Product: 10.0\n",
      "\n",
      "Index of minimum: 1\n",
      "\n",
      "Index of maximum: 2\n",
      "\n",
      "Squared difference: [  0   4  16  36 100]\n",
      "\n",
      "Original dtype of x_var: <dtype: 'int32'>\n",
      "\n",
      "New dtype of x_var: <dtype: 'float32'>\n",
      "\n",
      "Sum: [4. 4. 4.]\n",
      "\n",
      "Difference: [-2.  0.  2.]\n",
      "\n",
      "Product: [3. 4. 3.]\n",
      "\n",
      "Division: [0.33333334 1.         3.        ]\n",
      "\n",
      "Dot Product: 10.0\n",
      "\n",
      "Index of minimum: 1\n",
      "\n",
      "Index of maximum: 2\n",
      "\n",
      "Squared difference: [  0   4  16  36 100]\n",
      "\n",
      "Original dtype of x_var: <dtype: 'int32'>\n",
      "\n",
      "New dtype of x_var: <dtype: 'float32'>\n",
      "\n",
      "Concatenated Row-wise:\n",
      " [[3 6 9]\n",
      " [7 7 7]\n",
      " [4 5 6]\n",
      " [5 5 5]]\n",
      "\n",
      "Concatenated Column-wise:\n",
      " [[3 6 9 4 5 6]\n",
      " [7 7 7 5 5 5]]\n",
      "\n",
      "Stacked:\n",
      " [[3 7]\n",
      " [6 7]\n",
      " [9 7]]\n",
      "\n",
      "Mean of x: 2.75\n",
      "\n",
      "Mean across rows: [1.5 4. ]\n",
      "\n",
      "Mean across columns: [[3. ]\n",
      " [2.5]]\n",
      "\n",
      "Random Normal:\n",
      " [[ 7.562291 11.78431 ]\n",
      " [10.549743  8.480796]\n",
      " [ 8.059488 11.451664]]\n",
      "\n",
      "Random Uniform:\n",
      " [[0.49796402 0.641899  ]\n",
      " [0.38124442 0.8763828 ]\n",
      " [0.673524   0.45971298]]\n",
      "\n",
      "Softmax probabilities: [0.8756006  0.00589975 0.11849965]\n",
      "\n",
      "Square of 6: 36.0\n",
      "\n",
      "Concatenated Column-wise:\n",
      " [[3 6 9 4 5 6]\n",
      " [7 7 7 5 5 5]]\n",
      "\n",
      "Stacked:\n",
      " [[3 7]\n",
      " [6 7]\n",
      " [9 7]]\n",
      "\n",
      "Mean of x: 2.75\n",
      "\n",
      "Mean across rows: [1.5 4. ]\n",
      "Mean across columns: [[3. ]\n",
      " [2.5]]\n",
      "\n",
      "Random Normal:\n",
      " [[ 8.898783   7.4529724]\n",
      " [ 6.855311  12.260334 ]\n",
      " [ 8.779578   8.497919 ]]\n",
      "\n",
      "Random Uniform:\n",
      " [[0.37444246 0.34443772]\n",
      " [0.05849326 0.8929701 ]\n",
      " [0.14037323 0.759094  ]]\n",
      "\n",
      "Softmax probabilities: [0.8756006  0.00589975 0.11849965]\n",
      "\n",
      "Square of 6: 36.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "x = tf.constant([1.0, 2.0, 3.0])\n",
    "y = tf.constant([3.0, 2.0, 1.0])\n",
    "\n",
    "\n",
    "sum_result = tf.add(x, y)\n",
    "print(\"\\nSum:\", sum_result.numpy())\n",
    "\n",
    "difference = tf.subtract(x, y)\n",
    "print(\"\\nDifference:\", difference.numpy())\n",
    "\n",
    "\n",
    "product = tf.multiply(x, y)\n",
    "print(\"\\nProduct:\", product.numpy())\n",
    "\n",
    "\n",
    "division = tf.divide(x, y)\n",
    "print(\"\\nDivision:\", division.numpy())\n",
    "\n",
    "\n",
    "dot_product = tf.reduce_sum(tf.multiply(x, y))\n",
    "print(\"\\nDot Product:\", dot_product.numpy())\n",
    "\n",
    "\n",
    "x_min = tf.constant([10, 0, 13, 9])\n",
    "print(\"\\nIndex of minimum:\", tf.argmin(x_min).numpy())\n",
    "print(\"\\nIndex of maximum:\", tf.argmax(x_min).numpy())\n",
    "\n",
    "\n",
    "x_var = tf.Variable([1, 3, 5, 7, 11])\n",
    "y_var = tf.Variable([1])\n",
    "squared_diff = tf.math.squared_difference(x_var, y_var)\n",
    "print(\"\\nSquared difference:\", squared_diff.numpy())\n",
    "\n",
    "\n",
    "print(\"\\nOriginal dtype of x_var:\", x_var.dtype)\n",
    "x_var = tf.cast(x_var, dtype=tf.float32)\n",
    "print(\"\\nNew dtype of x_var:\", x_var.dtype)\n",
    "\n",
    "\n",
    "x_matrix = [[3, 6, 9], [7, 7, 7]]\n",
    "y_matrix = [[4, 5, 6], [5, 5, 5]]\n",
    "concat_rows = tf.concat([x_matrix, y_matrix], 0)\n",
    "\n",
    "\n",
    "x = tf.constant([1.0, 2.0, 3.0])\n",
    "y = tf.constant([3.0, 2.0, 1.0])\n",
    "\n",
    "\n",
    "sum_result = tf.add(x, y)\n",
    "print(\"\\nSum:\", sum_result.numpy())\n",
    "\n",
    "\n",
    "difference = tf.subtract(x, y)\n",
    "print(\"\\nDifference:\", difference.numpy())\n",
    "\n",
    "\n",
    "product = tf.multiply(x, y)\n",
    "print(\"\\nProduct:\", product.numpy())\n",
    "\n",
    "\n",
    "division = tf.divide(x, y)\n",
    "print(\"\\nDivision:\", division.numpy())\n",
    "\n",
    "\n",
    "dot_product = tf.reduce_sum(tf.multiply(x, y))\n",
    "print(\"\\nDot Product:\", dot_product.numpy())\n",
    "\n",
    "\n",
    "x_min = tf.constant([10, 0, 13, 9])\n",
    "print(\"\\nIndex of minimum:\", tf.argmin(x_min).numpy())\n",
    "print(\"\\nIndex of maximum:\", tf.argmax(x_min).numpy())\n",
    "\n",
    "\n",
    "x_var = tf.Variable([1, 3, 5, 7, 11])\n",
    "y_var = tf.Variable([1])\n",
    "squared_diff = tf.math.squared_difference(x_var, y_var)\n",
    "print(\"\\nSquared difference:\", squared_diff.numpy())\n",
    "\n",
    "print(\"\\nOriginal dtype of x_var:\", x_var.dtype)\n",
    "x_var = tf.cast(x_var, dtype=tf.float32)\n",
    "print(\"\\nNew dtype of x_var:\", x_var.dtype)\n",
    "\n",
    "\n",
    "x_matrix = [[3, 6, 9], [7, 7, 7]]\n",
    "y_matrix = [[4, 5, 6], [5, 5, 5]]\n",
    "concat_rows = tf.concat([x_matrix, y_matrix], 0)\n",
    "print(\"\\nConcatenated Row-wise:\\n\", concat_rows.numpy())\n",
    "\n",
    "concat_columns = tf.concat([x_matrix, y_matrix], 1)\n",
    "print(\"\\nConcatenated Column-wise:\\n\", concat_columns.numpy())\n",
    "\n",
    "\n",
    "stacked = tf.stack(x_matrix, axis=1)\n",
    "print(\"\\nStacked:\\n\", stacked.numpy())\n",
    "\n",
    "\n",
    "x_mean = tf.Variable([[1.0, 5.0], [2.0, 3.0]])\n",
    "print(\"\\nMean of x:\", tf.reduce_mean(input_tensor=x_mean).numpy())\n",
    "print(\"\\nMean across rows:\", tf.reduce_mean(input_tensor=x_mean, axis=0).numpy())\n",
    "print(\n",
    "    \"\\nMean across columns:\",\n",
    "    tf.reduce_mean(input_tensor=x_mean, axis=1, keepdims=True).numpy(),\n",
    ")\n",
    "\n",
    "\n",
    "random_normal = tf.random.normal(shape=(3, 2), mean=10.0, stddev=2.0)\n",
    "print(\"\\nRandom Normal:\\n\", random_normal.numpy())\n",
    "\n",
    "random_uniform = tf.random.uniform(\n",
    "    shape=(3, 2), minval=0, maxval=None, dtype=tf.float32\n",
    ")\n",
    "print(\"\\nRandom Uniform:\\n\", random_uniform.numpy())\n",
    "\n",
    "\n",
    "softmax_input = tf.constant([7.0, 2.0, 5.0])\n",
    "softmax_result = tf.nn.softmax(softmax_input)\n",
    "print(\"\\nSoftmax probabilities:\", softmax_result.numpy())\n",
    "\n",
    "\n",
    "def square(x):\n",
    "    return tf.multiply(x, x)\n",
    "\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    result = square(6.0)\n",
    "    print(\"\\nSquare of 6:\", result.numpy())\n",
    "(\"Concatenated Row-wise:\\n\", concat_rows.numpy())\n",
    "\n",
    "concat_columns = tf.concat([x_matrix, y_matrix], 1)\n",
    "print(\"\\nConcatenated Column-wise:\\n\", concat_columns.numpy())\n",
    "\n",
    "\n",
    "stacked = tf.stack(x_matrix, axis=1)\n",
    "print(\"\\nStacked:\\n\", stacked.numpy())\n",
    "\n",
    "\n",
    "x_mean = tf.Variable([[1.0, 5.0], [2.0, 3.0]])\n",
    "print(\"\\nMean of x:\", tf.reduce_mean(input_tensor=x_mean).numpy())\n",
    "print(\"\\nMean across rows:\", tf.reduce_mean(input_tensor=x_mean, axis=0).numpy())\n",
    "print(\n",
    "    \"Mean across columns:\",\n",
    "    tf.reduce_mean(input_tensor=x_mean, axis=1, keepdims=True).numpy(),\n",
    ")\n",
    "\n",
    "\n",
    "random_normal = tf.random.normal(shape=(3, 2), mean=10.0, stddev=2.0)\n",
    "print(\"\\nRandom Normal:\\n\", random_normal.numpy())\n",
    "\n",
    "random_uniform = tf.random.uniform(\n",
    "    shape=(3, 2), minval=0, maxval=None, dtype=tf.float32\n",
    ")\n",
    "print(\"\\nRandom Uniform:\\n\", random_uniform.numpy())\n",
    "\n",
    "\n",
    "softmax_input = tf.constant([7.0, 2.0, 5.0])\n",
    "softmax_result = tf.nn.softmax(softmax_input)\n",
    "print(\"\\nSoftmax probabilities:\", softmax_result.numpy())\n",
    "\n",
    "\n",
    "def square(x):\n",
    "    return tf.multiply(x, x)\n",
    "\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    result = square(6.0)\n",
    "    print(\"\\nSquare of 6:\", result.numpy())4=-=="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
